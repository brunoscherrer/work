\documentclass{article}
\usepackage{fullpage}
\usepackage[utf8x]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{autonum}
\usepackage{dsfont}
\usepackage{stmaryrd}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}


\title{A strongly polynomial algorithm for payoff games}

\author{Bruno Scherrer}
\def\R{\mathds R}
\def\1{{\mathds 1}}

\newcommand{\intset}[1]{\llbracket #1 \rrbracket}
\newcommand{\intpart}[1]{\lceil #1 \rceil}

\begin{document}
\maketitle

\begin{abstract}
...
\end{abstract}


Solve the $n$-horizon problem
\begin{align}
  T_{\vec\mu,\vec\nu} v = T^n v.
\end{align}


\begin{lemma}
  For any policy $\mu$, for any $x$, there exist $y$, $v \le i < i+c \le n$, such that
  \begin{align}
    v_{\mu}(x) - T^{n} v \le \frac{\gamma^{i+c}}{1-\gamma^c} \1_y (T^{n-i} v - T^{n-i-c} v).
  \end{align}
\end{lemma}
\begin{proof}
$\mu_*$ play against $\vec\nu$. Once a cycle is found, one loops.
\end{proof}

\begin{align}
  M_{x,y,i,c} = \{ \mu ~;~ \}
\end{align}

\begin{lemma}
  For any policy $\nu$, for any $x$, there exist $y$,  $v \le i < i+c \le n$, such that
  \begin{align}
    v_{\vec\mu_1^i(\vec\mu_{i+1}^{i+c})^\infty,\nu^\infty}(x) - T^{n} v \ge \frac{\gamma^i}{1-\gamma^c} \1_y (T^{n-i} v - T^{n-i-c} v).
  \end{align}
\end{lemma}
\begin{proof}
  $\vec\mu$ plays against $\nu$. Once a cycle is found, one loops.
\end{proof}

Algorithm: compute a policy $\mu'$ that is better than $(\vec\mu_{i+1}^{i+c})^\infty$ for all $i$ and $c$. From any $x$, $\mu'$ will end up cycling in $y$.

Warm-up: write the proof for the 1-player problem.

\bibliographystyle{plain}
\bibliography{biblio}


\end{document}


