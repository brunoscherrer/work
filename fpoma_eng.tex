\documentclass{article}
\usepackage{fullpage}
\usepackage[utf8x]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{autonum}
\usepackage{dsfont}

\newtheorem{theorem}{Théorème}
\newtheorem{lemma}{Lemme}
\newtheorem{remark}{Remarque}


\title{A Polynomial-Time Solution for Max-Affine Fixed-Point Equations}

\author{Bruno Scherrer\footnote{INRIA, bruno.scherrer@inria.fr}}

\date{December 26, 2025}


\def\1{{\mathds 1}}
\def\N{\mathbb N}
\def\E{\mathbb E}
\def\R{\mathbb R}
\def\={\stackrel{def}{=}}


\begin{document}
\maketitle


\begin{abstract}
We consider systems of max-affine fixed-point equations with at most one solution and propose a polynomial-time algorithm to compute the solution or decide there is none. The algorithm solves a sequence of linear programs and removes constraints that cannot participate in the solution, ensuring correctness and polynomial complexity. This approach applies to several well-known problems in theoretical computer science, including stochastic games, mean-payoff games, parity games, and linear complementarity problems with P-matrices. The results are preliminary, have not been peer-reviewed and may contain errors or important gaps; feedback and corrections are welcome. 
\end{abstract}

\paragraph{Disclaimer:} \emph{This preprint proposes a simple solution to some open problems in computer science. It has not been peer-reviewed and may contain errors or important gaps. Feedback and corrections are welcome.}

~\\

We consider a system of fixed-point equations of a max-affine operator on $\mathbb{R}^n$:
\begin{align}
\forall i,~~ x_i &= \max_{k \in K_i} [T^{(k)} x]_i  \label{fp}
\end{align}
where for each $k$ and any $y \in \mathbb{R}^n$, $T^{(k)} y$ is a vector in $\mathbb{R}^n$ whose $i$-th coordinate is:
\begin{align}
[T^{(k)} y]_i = \sum_j a^{(k)}_{ij} y_j + b^{(k)}_i.
\end{align}

We assume that there is either one solution $x^*$ or none to this system.

We describe an iterative algorithm indexed by $t$ to compute $x^*$ or decide there is no solution.

At $t=0$, for each $i$, we set $K_i^{(0)} = K_i$.

At each step $t$, we consider the optimization problem
\begin{align}
\min_{x \in \mathbb{R}^n} ~ \max_{i, k \in K_i^{(t)}} ~~ x_i - [T^{(k)} x]_i \label{lp} \\
\text{subject to: } \forall i,~~ \forall k \in K_i^{(t)},~~ x_i \ge [T^{(k)} x]_i.
\end{align}
It is easy to see that this is a linear program.

Let $z^{(t)}$ be the optimum of problem \eqref{lp}, and $(x^{(t)}, i^{(t)}, k^{(t)})$ a tuple of indices corresponding to an optimal solution.

\begin{itemize}
\item If $z^{(t)} = 0$, the algorithm terminates, and $x^*$ is the solution of the linear system
\begin{align}
\forall i,~~ \forall k \in K_i^{(t)},~~ x_i = [T^{(k)} x]_i.
\end{align}

\item If $z > 0$, we update the sets as follows:
\begin{align}
K^{(t+1)}_{i^{(t)}} &= K^{(t)}_{i^{(t)}} \setminus \{ k^{(t)} \} \\
\forall i \neq i^{(t)}, ~~ K^{(t+1)}_i &= K^{(t)}_i
\end{align}
If $K^{(t+1)}_{i^(t)}$ is empty, then the algorithm terminates and we know that there is no solution. Otherwise we go on with the next iteration.


\end{itemize}

This algorithm stops after at most $\sum_i |K_i| - n$ iterations and linear program resolutions. By rewriting system \eqref{fp} using $n \sum_i \lceil \log_2 K_i \rceil$ variables and maxes over two parameters, the number of linear programs to solve can be reduced to $(n-1) \sum_i \lceil \log_2 K_i \rceil$.

~\\

The correctness of the algorithm follows from the fact (true at iteration 0 and inherited at each subsequent iteration) that as long as the constraint set of the linear program \eqref{lp} contains the solution $x^*$, at each step $t$ we have
\begin{align}
x^*_{i^{(t)}} - [T^{(k^{(t)})} x^*]_{i^{(t)}} \ge x^{(t)}_{i^{(t)}} - [T^{(k^{(t)})} x^{(t)}]_{i^{(t)}} = z > 0.
\end{align}
In other words, the constraint corresponding to indices $(i^{(t)}, k^{(t)})$ does not participate in the characterization of $x^*$, and can safely be removed.

~\\

A linear program with $n$ variables and an input encoding of size $L$ can be solved in time $\tilde O(n^3 L)$. Therefore, the algorithm described here has polynomial complexity $\tilde O(n^4 L)$. In particular, it allows solving in polynomial time several problems that can be expressed in the form \eqref{fp}:
\begin{itemize}
\item Turn-based stochastic games on a graph with discount factor $\gamma$ \cite{shapley1953stochastic} (with a dependence on $\log \frac{1}{1-\gamma}$);
\item Mean payoff games with discount factor $\gamma$ \cite{zwick} (with a dependence on $\log \frac{1}{1-\gamma}$);
\item Mean payoff games (by reduction to the mean payoff games with discount factor $\gamma = 1 - \frac{1}{4 n^3 W}$, where $W$ is a bound on the integer cost  \cite{zwick});
\item Parity games with $d$ priorities (by reduction to mean payoff games with maximum cost $W$ in $n^d$ \cite{puri});
\item Linear complementarity problems with a P-matrix (without dependence on the condition number of the matrix \cite{kojima}).
\end{itemize}


\bibliographystyle{plain}
\bibliography{biblio2.bib} 

\end{document}
